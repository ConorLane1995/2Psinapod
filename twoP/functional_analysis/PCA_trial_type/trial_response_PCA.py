"""
TODO
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from matplotlib.lines import Line2D
from scipy.io import loadmat
import seaborn as sns
import pickle
import json
import sys
import os

# more info: https://pietromarchesi.net/pca-neural-data.html

sys.path.append(os.path.abspath(os.path.dirname(__file__)) + '/../../')
from utils import get_active_cells

# load what we need from the config file
with open(os.path.abspath(os.path.dirname(__file__)) +'/../../../config.json','r') as f:
    config = json.load(f)

BASE_PATH = config['RecordingFolder'] # folder with all of the files generated by Suite2P for this recording (F.npy, iscell.npy, etc)
CONDITIONS_PATH = config['Conditions'] # name of the CSV (assumed to be within BASE_PATH) with the condition types of each trial (freq, intensity, etc)
CELL_DICT = config['AnalysisFile'] # name of the file that all of the analysis is getting saved in (tuning, best frequency, etc)

ACTIVE_CELLS_ONLY = True

"""
TODO
"""
def standardize(data):
    # data: n_features x n_samples

    ss = StandardScaler(with_mean=True,with_std=True)
    data_c = ss.fit_transform(data.T).T
    return data_c

""" 
TODO
"""
def add_orientation_legend(ax,trial_types):
    pal = sns.color_palette('rocket_r', 13)
    custom_lines = [Line2D([0], [0], color=pal[k], lw=4) for
                    k in range(len(trial_types))]
    labels = ['{}'.format(t) for t in trial_types]
    ax.legend(custom_lines, labels,
              frameon=False, loc='center left', bbox_to_anchor=(1, 0.5))
    plt.tight_layout(rect=[0,0,0.9,1])


def main():
    data = np.load(BASE_PATH+"epoched_traces.npy")
    conditions_mat = loadmat(BASE_PATH+CONDITIONS_PATH) # conditition type of each trial in chronological order (row 1 = trial 1)
    conditions = conditions_mat["stim_data"]

    if ACTIVE_CELLS_ONLY:
        with open(BASE_PATH+CELL_DICT,"rb") as f:
            cell_dict = pickle.load(f)

        active_cell_dict = get_active_cells(cell_dict)
        active_cell_IDs = np.array(list(active_cell_dict.keys()))
        all_IDs = np.array(list(cell_dict.keys()))
        active_cell_idx = np.nonzero(np.in1d(all_IDs,active_cell_IDs))[0]

        epoched_data = data[active_cell_idx,:,:]


    # trials a list of K Numpy arrays of shape NÃ—T (number of neurons by number of time points).
    trials = []
    for trial_idx in range(len(epoched_data[0])):
        trials.append(epoched_data[:,trial_idx,:])

    trial_type = conditions[:,0]

    trial_types = np.unique(conditions[:,0])

    Xr = np.vstack([t[:,4:].mean(axis=1) for t in trials]).T
    Xr_sc = standardize(Xr)

    pca = PCA(n_components=15)
    Xp = pca.fit_transform(Xr_sc.T).T
    
    trial_types = list(reversed(trial_types))

    pal = sns.color_palette('rocket_r', 13)
    projections = [(0, 1), (1, 2), (0, 2)]
    fig, axes = plt.subplots(1, 3, figsize=[9, 3], sharey='row', sharex='row')
    for ax, proj in zip(axes, projections):
        for t, t_type in enumerate(trial_types):
            x = Xp[proj[0], np.nonzero(trial_type==t_type)]
            y = Xp[proj[1], np.nonzero(trial_type==t_type)]
            print(len(x[0]))
            total_points += len(x[0])
            ax.scatter(x, y, c=pal[t], s=30, alpha=0.7)
            ax.set_xlabel('PC {}'.format(proj[0]+1))
            ax.set_ylabel('PC {}'.format(proj[1]+1))

    sns.despine(fig=fig, top=True, right=True)

    add_orientation_legend(axes[2],trial_types)
    print(pca.explained_variance_ratio_)
    plt.show()


if __name__=="__main__":
    main()