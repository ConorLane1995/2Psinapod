{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_active_cells(deconvolved_traces):\n",
    "\n",
    "    # going to return a dictionary with only active cells, formatted exactly the same as traces\n",
    "\n",
    "    d = dict.fromkeys(deconvolved_traces.keys())\n",
    "\n",
    "    for cell in deconvolved_traces:\n",
    "        if deconvolved_traces[cell]['active'] == True:\n",
    "            d[cell] = deconvolved_traces[cell]\n",
    "        else:\n",
    "            d.pop(cell,None)\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH_1 = \"F:/Two-Photon/Psilocybin Project/Evoked Cohort Mice/ID474/psilo/TSeries-10132023-1324-142/suite2p/plane0/\"\n",
    "BASE_PATH_2 = \"F:/Two-Photon/Psilocybin Project/Evoked Cohort Mice/ID474/psilo/TSeries-10132023-1324-143/suite2p/plane0/\"\n",
    "file_path = \"F:/Two-Photon/Psilocybin Project/Evoked Cohort Mice/ID474/psilo/TSeries-10132023-1324-143/suite2p/plane0/roimatch_142_143.csv\"\n",
    "\n",
    "iscellpath_1 = BASE_PATH_1 + \"iscell.npy\"\n",
    "tracepath_1 = BASE_PATH_1 + \"F.npy\"\n",
    "cell_dict_1 = BASE_PATH_1 + \"cells.pkl\"\n",
    "\n",
    "iscellpath_2 = BASE_PATH_2 + \"iscell.npy\"\n",
    "tracepath_2 = BASE_PATH_2 + \"F.npy\"\n",
    "cell_dict_2 = BASE_PATH_2 + \"cells.pkl\"\n",
    "\n",
    "\n",
    "iscell_1 = np.load(iscellpath_1)\n",
    "traces_1 = np.load(tracepath_1)\n",
    "\n",
    "iscell_2 = np.load(iscellpath_2)\n",
    "traces_2 = np.load(tracepath_2)\n",
    "\n",
    "\n",
    "with open(cell_dict_1, 'rb') as f:\n",
    "    cell_dict_1 = pickle.load(f)\n",
    "\n",
    "with open(cell_dict_2, 'rb') as f:\n",
    "    cell_dict_2 = pickle.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI_indices_1 = (iscell_1[:,0] == 1).nonzero()\n",
    "ROI_indices_1 = ROI_indices_1[0] # extracting the first part of the tuple\n",
    "cell_IDs_1 = ROI_indices_1 + 1 # add 1 so we don't have zero indexing\n",
    "\n",
    "# print(cell_IDs_1[436])\n",
    "\n",
    "ROI_indices_2 = (iscell_2[:,0] == 1).nonzero()\n",
    "ROI_indices_2 = ROI_indices_2[0] # extracting the first part of the tuple\n",
    "cell_IDs_2 = ROI_indices_2 + 1 # add 1 so we don't have zero indexing\n",
    "\n",
    "# print(cell_IDs_2[255])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 117 matched cells in first and 117 in second recording (should be the same)\n",
      "46 active cells detected in pre- recording\n",
      "50 active cells detected in post- recording\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load the CSV file into a NumPy array\n",
    "matched_cells = np.genfromtxt(file_path, delimiter=',', skip_header=0)\n",
    "matched_cells = matched_cells.astype(int) - 1  # Subtract 1 and convert to int in one step\n",
    "\n",
    "# Extract columns 0 and 1\n",
    "column_0 = matched_cells[:, 0]\n",
    "column_1 = matched_cells[:, 1]\n",
    "\n",
    "# Retrieve lists using NumPy indexing\n",
    "cell_array = np.zeros_like(matched_cells)\n",
    "cell_array[:,0] = cell_IDs_1[column_0]\n",
    "cell_array[:,1] = cell_IDs_2[column_1]\n",
    "\n",
    "print(\"Detected\", len(cell_array[:,0]), \"matched cells in first and\",len(cell_array[:,1]), \"in second recording (should be the same)\")\n",
    "\n",
    "\n",
    "active_1 = get_active_cells(cell_dict_1)\n",
    "\n",
    "matched_active_1 = [cell for cell in cell_array[:,0] if cell in active_1.keys()]\n",
    "\n",
    "print(len(matched_active_1), \"active cells detected in pre- recording\")\n",
    "\n",
    "active_2 = get_active_cells(cell_dict_2)\n",
    "\n",
    "matched_active_2 = [cell for cell in cell_array[:,1] if cell in active_2.keys()]\n",
    "\n",
    "print(len(matched_active_2), \"active cells detected in post- recording\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 31 cells responsive in both recordings\n",
      "There were 15 cells responsive only in the first recording\n",
      "There were 19 cells responsive only in the second recording\n",
      "There were 65 cells responsive in at least one recording\n"
     ]
    }
   ],
   "source": [
    "#  Make a two column array containing each cell and it's matched cell. \n",
    "\n",
    "coactive_cells = []\n",
    "responded_in_minimum_one = []\n",
    "became_inactive = []\n",
    "became_active = []\n",
    "\n",
    "\n",
    "for i, (cell_1, cell_2) in enumerate(cell_array):\n",
    "    if cell_1 in matched_active_1 and cell_2 in matched_active_2:\n",
    "        coactive_cells.append(cell_array[i, :])\n",
    "    elif cell_1 in matched_active_1 and cell_2 not in matched_active_2:\n",
    "        became_inactive.append(cell_array[i,0])\n",
    "    elif cell_1 not in matched_active_1 and cell_2 in matched_active_2:\n",
    "        became_active.append(cell_array[i,0])\n",
    "    if cell_1 in matched_active_1 or cell_2 in matched_active_2:\n",
    "        responded_in_minimum_one.append(cell_array[i, :])\n",
    "\n",
    "# Convert the list of coactive_cells to a NumPy array\n",
    "coactive_cells_array = np.array(coactive_cells)\n",
    "active_only_first_array = np.array(became_inactive)\n",
    "active_only_second_array = np.array(became_active)\n",
    "active_in_minimum_one_array = np.array(responded_in_minimum_one)\n",
    "print(\"There were\", len(coactive_cells_array),\"cells responsive in both recordings\")\n",
    "print(\"There were\", len(became_inactive),\"cells responsive only in the first recording\")\n",
    "print(\"There were\", len(became_active),\"cells responsive only in the second recording\")\n",
    "print(\"There were\", len(responded_in_minimum_one),\"cells responsive in at least one recording\")\n",
    "\n",
    "np.save(BASE_PATH_2 + \"coactive_cells_array\",coactive_cells_array)\n",
    "np.save(BASE_PATH_2 + \"active_only_first\",active_only_first_array)\n",
    "np.save(BASE_PATH_2 + \"active_only_second\",active_only_first_array)\n",
    "np.save(BASE_PATH_2 + \"matched_cells\",cell_array)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  13   40]\n",
      " [  16   31]\n",
      " [  21   12]\n",
      " [  57  565]\n",
      " [ 106 1040]\n",
      " [ 111  590]\n",
      " [ 124  322]\n",
      " [ 134  289]\n",
      " [ 147  124]\n",
      " [ 152  223]\n",
      " [ 154   70]\n",
      " [ 155  222]\n",
      " [ 172  120]\n",
      " [ 177  520]\n",
      " [ 182  102]\n",
      " [ 183  154]\n",
      " [ 185  591]\n",
      " [ 206   68]\n",
      " [ 223  155]\n",
      " [ 284   73]\n",
      " [ 323  548]\n",
      " [ 382  110]\n",
      " [ 385  181]\n",
      " [ 390  159]\n",
      " [ 431   72]\n",
      " [ 460  188]\n",
      " [ 560  131]\n",
      " [ 639  197]\n",
      " [ 732  434]\n",
      " [ 801  285]\n",
      " [1018  278]]\n"
     ]
    }
   ],
   "source": [
    "print(coactive_cells_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 13, 16, 21, 24, 30, 41, 49, 57, 70, 83, 106, 107, 111, 120, 124, 134, 147, 152, 154, 155, 172, 177, 178, 182, 183, 185, 206, 223, 231, 284, 323, 382, 385, 390, 431, 460, 483, 560, 615, 639, 732, 768, 801, 852, 1018]\n",
      "[1, 264, 40, 31, 12, 490, 116, 565, 79, 370, 164, 456, 1040, 590, 322, 289, 124, 223, 70, 222, 120, 520, 562, 102, 154, 591, 68, 155, 140, 578, 158, 143, 73, 109, 548, 451, 110, 181, 159, 72, 188, 543, 131, 221, 197, 627, 434, 285, 1045, 278]\n"
     ]
    }
   ],
   "source": [
    "print(matched_active_1)\n",
    "print(matched_active_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary Additions:\n",
    "\n",
    "#  Add a section to the post dictionary entitled 'matches' containing the array of matched cells.  \n",
    "# Don't need more than this as you can work everything out from these. \n",
    "\n",
    "for cell_1, cell_2 in zip(cell_dict_1.keys(), cell_dict_2.keys()):\n",
    "    cell_dict_1[cell_1]['matched_cells'] = cell_array\n",
    "    cell_dict_2[cell_2]['matched_cells'] = cell_array\n",
    "\n",
    "with open(BASE_PATH_1+'cells.pkl','wb') as f:\n",
    "        pickle.dump(cell_dict_1,f)\n",
    "\n",
    "with open(BASE_PATH_2+'cells.pkl','wb') as f:\n",
    "        pickle.dump(cell_dict_2,f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
