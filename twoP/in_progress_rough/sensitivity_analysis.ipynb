{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Author: Conor Lane, February 2024\n",
    "Contact: conor.lane1995@gmail.com\n",
    "\n",
    "Analysis code for calculating sensitivity of both all individual cells, and changes in sensitivity between pre- and post- for the randomized stim cohort. \n",
    "Sensitivity = the lowest intensity at which a cell shows a significant response to sound-stimulation. \n",
    "\n",
    "INPUTS: filepath to the evoked cohort megadicts (collected recordings for each condition from Evoked Cohort)\n",
    "        z_thresh - minimum z-score threshold over which we declare a significant response (default is 4).\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import pandas as pd\n",
    "import scipy.stats as ss\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from scipy.stats import kstest\n",
    "import os\n",
    "\n",
    "z_thresh = 4\n",
    "filepath = \"F:/Two-Photon/Psilocybin Project/Evoked Cohort Mice/megadicts\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD RANDOMIZED STIM COHORT DICTS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to map filenames to variable names\n",
    "file_variable_mapping = {\n",
    "    'saline_pre_dict.pkl': 'saline_pre',\n",
    "    'saline_post_dict.pkl': 'saline_post',\n",
    "    'psilo_pre_dict.pkl': 'psilo_pre',\n",
    "    'psilo_post_dict.pkl': 'psilo_post'\n",
    "}\n",
    "\n",
    "# Initialize empty dictionaries\n",
    "saline_pre = {}\n",
    "saline_post = {}\n",
    "psilo_pre = {}\n",
    "psilo_post = {}\n",
    "\n",
    "# Iterate through files in megadict folder\n",
    "for filename in os.listdir(filepath):\n",
    "    if filename in file_variable_mapping:\n",
    "        file_path = os.path.join(filepath, filename)\n",
    "        with open(file_path, 'rb') as file:\n",
    "            # Load pkl file and assign to respective dictionary variable\n",
    "            globals()[file_variable_mapping[filename]] = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GENERAL FUNCTIONS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots a double-bar graph for two chosen sensitivity arrays. \n",
    "# INPUTS: values_set_1 and 2 - the two sets of sensitivities to compare\n",
    "#         title - title of graph as string\n",
    "#         label_1 - first bar label e.g. Pre-Saline\n",
    "#         label_2 - second bar label\n",
    "\n",
    "def calculate_relative_frequencies(values, unique_values):\n",
    "    total_values = len(values)\n",
    "    frequencies = np.array([np.sum(values == value) / total_values for value in unique_values])\n",
    "    return frequencies\n",
    "\n",
    "def plot_comparison(values_set1, values_set2,title,label_1,label_2):\n",
    "    # Calculate unique values for each set\n",
    "    unique_values_set1 = np.unique(values_set1)\n",
    "    unique_values_set2 = np.unique(values_set2)\n",
    "    \n",
    "    # Combine unique values from both sets\n",
    "    unique_values = np.unique(np.concatenate((unique_values_set1, unique_values_set2)))\n",
    "\n",
    "    # Halve the unique values except for 0\n",
    "    halved_unique_values = [value / 2 if value != 0 else 0 for value in unique_values]\n",
    "\n",
    "    # Calculate relative frequencies for each set based on the unique values\n",
    "    rel_freq_set1 = calculate_relative_frequencies(values_set1, unique_values)\n",
    "    rel_freq_set2 = calculate_relative_frequencies(values_set2, unique_values)\n",
    "\n",
    "    # Set the width of the bars\n",
    "    bar_width = 0.35\n",
    "\n",
    "    # Set the positions of the bars on the x-axis\n",
    "    r1 = np.arange(len(unique_values))\n",
    "    r2 = [x + bar_width for x in r1]\n",
    "\n",
    "    # Create the bar plot\n",
    "    plt.bar(r1, rel_freq_set1, color='blue', width=bar_width, edgecolor='black', label=label_1)\n",
    "    plt.bar(r2, rel_freq_set2, color='orange', width=bar_width, edgecolor='black', label=label_2)\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel('Bandwidth (Octaves)')\n",
    "    plt.ylabel('Probability')\n",
    "    plt.title(title)\n",
    "\n",
    "    # Set the modified x tick labels\n",
    "    plt.xticks([r + bar_width / 2 for r in range(len(unique_values))], halved_unique_values)\n",
    "\n",
    "    # Add legend\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array of all the matched cells that are sound-responsive in both recordings.  Each row is a matched cell pair. \n",
    "# INPUTS:  pre- and post- megadicts for a given drug condition. \n",
    "#          The specific recording to get matched cells for in the sub-dictionaries of pre- and post.\n",
    "#          Code is written to be used with the matched cells bandwidth functions. \n",
    "# OUTPUTS: (npairs x 2) array containing the matched cell pairs that were responsive in both recordings. \n",
    "\n",
    "def get_consistently_responsive_cells(dict_pre,dict_post,sub_dict_pre,sub_dict_post):\n",
    "\n",
    "    matched_responsive_1 = []\n",
    "    matched_responsive_2 = []\n",
    "\n",
    "    # Get the array of matched cell pairs stored under the dictionary's first cell key. \n",
    "    matched_cells = dict_post[sub_dict_post][next(iter(dict_post[sub_dict_post]))]['matched_cells']\n",
    "\n",
    "    # iterate through each cell in the first dict and check if it is a matched cell pair.  Append the matched cells to a list.\n",
    "    for cell in dict_pre[sub_dict_pre]:\n",
    "            if cell in matched_cells[:,0] and dict_pre[sub_dict_pre][cell]['active'] == True:\n",
    "                matched_responsive_1.append(cell)\n",
    "\n",
    "    # Same operation but with the second dictionary.\n",
    "    for cell in dict_post[sub_dict_post]:\n",
    "            if cell in matched_cells[:,1] and dict_post[sub_dict_post][cell]['active'] == True:\n",
    "                matched_responsive_2.append(cell)\n",
    "\n",
    "    indices = np.where(np.isin(matched_cells[:, 0], matched_responsive_1))\n",
    "\n",
    "    # Find the indices where the values in column 0 appear in the first match list.\n",
    "    indices_col1 = np.isin(matched_cells[:, 0], matched_responsive_1)\n",
    "\n",
    "    # Find the indices where the values in column 1 appear in the second match list. \n",
    "    indices_col2 = np.isin(matched_cells[:, 1], matched_responsive_2)\n",
    "\n",
    "    # Combine the two conditions using logical AND\n",
    "    combined_indices = np.logical_and(indices_col1, indices_col2)\n",
    "\n",
    "    # Extract the rows where both conditions are true\n",
    "    coactive = matched_cells[combined_indices]\n",
    "\n",
    "    return coactive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cdf(data):\n",
    "    # Define your series\n",
    "    s = pd.Series(data, name = 'value')\n",
    "    df = pd.DataFrame(s)\n",
    "    # Get the frequency, PDF and CDF for each value in the series\n",
    "\n",
    "    # Frequency\n",
    "    stats_df = df \\\n",
    "    .groupby('value') \\\n",
    "    ['value'] \\\n",
    "    .agg('count') \\\n",
    "    .pipe(pd.DataFrame) \\\n",
    "    .rename(columns = {'value': 'frequency'})\n",
    "\n",
    "    # PDF\n",
    "    stats_df['pdf'] = stats_df['frequency'] / sum(stats_df['frequency'])\n",
    "\n",
    "    # CDF\n",
    "    stats_df['cdf'] = stats_df['pdf'].cumsum()\n",
    "    stats_df = stats_df.reset_index()\n",
    "    stats_df\n",
    "\n",
    "    return stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cdf(pre,post,title,label_1,label_2):\n",
    "    pre_cdf = calculate_cdf(pre)\n",
    "    post_cdf = calculate_cdf(post)\n",
    "\n",
    "    label = [label_1,label_2]\n",
    "\n",
    "    zipped = zip([pre_cdf,post_cdf], label)\n",
    "\n",
    "    fig = plt.figure()\n",
    "\n",
    "    for frame,label in zipped:\n",
    "        plt.plot(frame['value'], frame['cdf'],label = label )\n",
    "    plt.title(title,pad=10)\n",
    "    plt.xticks(range(4), [35,50,65,80])\n",
    "    plt.xlabel(\"Lowest Response Intensity (dB)\")\n",
    "    plt.ylabel(\"Cumulative Probability\")\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FUNCTIONS ALL CELLS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sensitivity_all_cells(dict):\n",
    "    \n",
    "    sensitivity_all = []\n",
    "\n",
    "    sub_dict_keys = dict.keys()\n",
    "\n",
    "    for sub_dict in sub_dict_keys:\n",
    "        for cell in dict[sub_dict]:\n",
    "\n",
    "            if dict[sub_dict][cell]['active'] == True:\n",
    "                tuning_array = np.array(dict[sub_dict][cell]['peak_tuning'])\n",
    "                for i in range(len(tuning_array[0,:])):\n",
    "                    if any(y > z_thresh for y in tuning_array[0:,i]):\n",
    "                        sensitivity_all.append(float(i))\n",
    "                        break\n",
    "                    else:\n",
    "                        continue\n",
    "\n",
    "    return sensitivity_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FUNCTIONS MATCHED CELLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lowest_response_intensity_matched(dict_pre,dict_post):\n",
    "        \n",
    "        lowest_response_intensity_all = []\n",
    "\n",
    "        for sub_dict_pre, sub_dict_post in zip(dict_pre.keys(),dict_post.keys()):\n",
    "\n",
    "        \n",
    "\n",
    "                # Get the array of consistently responsive matched cell pairs for the pre- and post-conditions. \n",
    "                coactive = get_consistently_responsive_cells(dict_pre,dict_post,sub_dict_pre,sub_dict_post)\n",
    "                \n",
    "                lowest_response_intensity = np.zeros_like(coactive)\n",
    "\n",
    "                for i,cell_1, cell_2 in zip(range(len(coactive[:,0])),coactive[:,0],coactive[:,1]):\n",
    "                        tuning_array_1 = dict_pre[sub_dict_pre][cell_1]['peak_tuning']\n",
    "                        tuning_array_2 = dict_post[sub_dict_post][cell_2]['peak_tuning']\n",
    "\n",
    "                        nInt = len(tuning_array_1[0,:])         \n",
    "                        \n",
    "                        for j in range(nInt):\n",
    "                                if np.any(tuning_array_1[0:,j] >= z_thresh): \n",
    "                                        lowest_response_intensity[i,0] = float(j)\n",
    "                                        break\n",
    "                                else:\n",
    "                                        continue\n",
    "                        \n",
    "                        for j in range(nInt):\n",
    "                                if np.any(tuning_array_2[0:,j] >= z_thresh): \n",
    "                                        lowest_response_intensity[i,1] = float(j)\n",
    "                                        break\n",
    "                                else:\n",
    "                                        continue\n",
    "                                \n",
    "                lowest_response_intensity_all.append(lowest_response_intensity)\n",
    "        lowest_response_intensity_all = np.concatenate(lowest_response_intensity_all)\n",
    "\n",
    "        return lowest_response_intensity_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low = get_lowest_response_intensity_matched(saline_pre,saline_post)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANALYSIS: ALL CELLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate lowest response intensity Saline\n",
    "sensitivity_pre_saline = get_sensitivity_all_cells(saline_pre)\n",
    "sensitivity_post_saline = get_sensitivity_all_cells(saline_post)\n",
    "\n",
    "# Calculate lowest response intensity Psilocybin\n",
    "sensitivity_pre_psilo = get_sensitivity_all_cells(psilo_pre)\n",
    "sensitivity_post_psilo = get_sensitivity_all_cells(psilo_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "statistic, p_value = mannwhitneyu(sensitivity_post_saline, sensitivity_post_psilo)\n",
    "\n",
    "print(f\"Mann-Whitney U statistic: {statistic}\")\n",
    "print(f\"P-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Cell Sensitivity Post-Saline and Post-Psilocybin'\n",
    "label_1 = 'Post-Saline'\n",
    "label_2 = 'Post-Psilocybin'\n",
    "plot_cdf(sensitivity_post_saline,sensitivity_post_psilo,title,label_1,label_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Cell Sensitivity Post-Saline and Post-Psilocybin'\n",
    "label_1 = 'Pre-Saline'\n",
    "label_2 = 'Post-Saline'\n",
    "plot_cdf(sensitivity_pre_saline,sensitivity_post_saline,title,label_1,label_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Cell Sensitivity Post-Saline and Post-Psilocybin'\n",
    "label_1 = 'Pre-Psilocybin'\n",
    "label_2 = 'Post-Psilocybin'\n",
    "plot_cdf(sensitivity_pre_saline,sensitivity_pre_psilo,title,label_1,label_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "statistic, p_value = mannwhitneyu(sensitivity_pre_saline, sensitivity_pre_psilo)\n",
    "\n",
    "print(f\"Mann-Whitney U statistic: {statistic}\")\n",
    "print(f\"P-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowest_saline = get_lowest_response_intensity_matched(saline_pre,saline_post)\n",
    "lowest_psilo = get_lowest_response_intensity_matched(psilo_pre,psilo_post)\n",
    "\n",
    "title = 'Cell Sensitivity Post-Saline and Post-Psilocybin'\n",
    "label_1 = 'Pre-Saline'\n",
    "label_2 = 'Post-Saline'\n",
    "plot_cdf(lowest_saline[:,1],lowest_psilo[:,1],title,label_1,label_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at changes in tuning specifically for the non-coactive cells"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
